{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ec33d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics                 import confusion_matrix\n",
    "from sklearn.metrics                 import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5d1657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_title', 'Persona'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta=pd.read_csv('/Users/nihz415/Desktop/benekiva/p2/test.csv')\n",
    "dta\n",
    "dta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de1fef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##clean\n",
    "def clean_text(text):\n",
    "    text=re.sub(r',',' ' ,text)\n",
    "    return text\n",
    "dta['tidy'] = dta['job_title'].astype('U').apply(clean_text)  \n",
    "dta['tidy']=dta['tidy'].str.lower()   \n",
    "dta['tidy'] = dta['tidy'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "\n",
    "def classify(text):\n",
    "    if text=='IT':\n",
    "        clf=2\n",
    "    else:        \n",
    "        if text=='Claims':\n",
    "            clf=1\n",
    "        else:\n",
    "            if text=='Executive':\n",
    "                clf=3\n",
    "            else:\n",
    "                clf=0\n",
    "    return (clf)                \n",
    "dta['target'] = dta['Persona'].astype('U').apply(classify)                 \n",
    "\n",
    "dta1=dta[['tidy','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97ca7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "947\n",
      "443\n",
      "401\n",
      "401\n",
      "401\n",
      "401\n"
     ]
    }
   ],
   "source": [
    "###undersampling\n",
    "pclass1 = dta1[dta1.target==1]\n",
    "pclass2 = dta1[dta1.target==2]\n",
    "pclass3 = dta1[dta1.target==3]\n",
    "count1, count2, count3 = dta1.target.value_counts()\n",
    "print(count1)\n",
    "print(count2)\n",
    "print(count3)\n",
    "\n",
    "\n",
    "under0 = pclass1.sample(count3,replace=True)\n",
    "under1 = pclass2.sample(count3,replace=True)\n",
    "dta2 = pd.concat([under0,under1,pclass3],axis=0)\n",
    "count1, count2, count3 = dta2.target.value_counts()\n",
    "print(count1)\n",
    "print(count2)\n",
    "print(count3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2ca8bf",
   "metadata": {},
   "source": [
    "# With Monte-Carlo, nmc=100 for average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d1e5b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####turn into corpusï¼Œ set X and y\n",
    "corpus= dta2['tidy'].to_list()   \n",
    "vectorizer_count= CountVectorizer(lowercase= True,ngram_range = (1,1),max_df= 0.85,min_df= 0.005);\n",
    "X=vectorizer_count.fit_transform(dta2['tidy'].values.astype('U'))\n",
    "features_frequency= pd.DataFrame({'feature':vectorizer_count.get_feature_names(),'feature_frequency' : X.toarray().sum(axis=0)})\n",
    "X.shape\n",
    "\n",
    "y = dta2.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9e00c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9734700665188473\n",
      "0.933654485049834\n"
     ]
    }
   ],
   "source": [
    "#########logistic\n",
    "lc = LogisticRegression(max_iter=1000,penalty=\"none\")\n",
    "# Set up randomized cross validation using standard Scikit-learn tools\n",
    "shuffle = ShuffleSplit(n_splits=100, test_size=.25)\n",
    "CVInfo = cross_validate(lc, X, y, cv=shuffle,return_train_score=True,n_jobs=-1)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed7750d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_neighbors= 50\n",
      "[0.9575747508305648, 0.9586378737541529, 0.9578405315614619, 0.9599999999999997, 0.9608970099667773, 0.9607641196013287, 0.9598671096345512, 0.9588039867109635, 0.9591029900332227, 0.9603322259136212]\n"
     ]
    }
   ],
   "source": [
    "#########knn\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try n_neighbors from 1 to 25\n",
    "neighbors_settings = range(10, 110,10)\n",
    "shuffle = ShuffleSplit(n_splits=100, test_size=.25)\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the model\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    CVInfo = cross_validate(knn, X, y, cv=shuffle,return_train_score=True,n_jobs=-1)\n",
    "    # record train accuracy\n",
    "    training_accuracy.append(np.mean(CVInfo['train_score']))\n",
    "    # record test accuracy\n",
    "    test_accuracy.append(np.mean(CVInfo['test_score']))\n",
    "\n",
    "nbest = np.argmax(test_accuracy)\n",
    "best_neighbors = neighbors_settings[nbest]\n",
    "print(\"best_neighbors=\",best_neighbors)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1da61ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9645232815964523\n",
      "0.9568106312292359\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=best_neighbors)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y )\n",
    "knn.fit(X_train,y_train)\n",
    "print(knn.score(X_train,y_train))\n",
    "print(knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c33f6e9",
   "metadata": {},
   "source": [
    "# Without Montecarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b72c1430",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "dta3=dta2[['tidy','target']]\n",
    "dta3['ML_group']  = np.random.randint(10,size=dta3.shape[0])\n",
    "dta3['ML_group']  = (dta3['ML_group']<=5)*0 + (dta3['ML_group']==6)*1 + (dta3['ML_group']==7)*1+(dta3['ML_group']==9)*2+(dta3['ML_group']==8)*2\n",
    "X_train = X[np.where(dta3['ML_group']==0)[0],:]\n",
    "X_valid = X[np.where(dta3['ML_group']==1)[0],:]\n",
    "X_test  = X[np.where(dta3['ML_group']==2)[0],:]\n",
    "y_train = dta3.loc[dta3['ML_group']==0,['target']]['target'].to_numpy()\n",
    "y_valid = dta3.loc[dta3['ML_group']==1,['target']]['target'].to_numpy()\n",
    "y_test  = dta3.loc[dta3['ML_group']==2,['target']]['target'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fa11912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[69,  0,  0],\n",
       "        [ 0, 73,  6],\n",
       "        [ 1,  5, 75]]),\n",
       " 0.9475982532751092)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "def logistic_reg_classifier_mult_labels(X_train,y_train,X_valid,y_valid,X_test,y_test):\n",
    "    \n",
    "    ' . '\n",
    "    categories         = pd.DataFrame(np.sort(np.unique(y_train))).reset_index()\n",
    "    categories.columns = ['index','label']\n",
    "    \n",
    "\n",
    "    ' . '    \n",
    "    ccp_train_list = []\n",
    "    ccp_valid_list = []\n",
    "    ccp_test_list  = []\n",
    "    for cat in categories['label'].to_list():\n",
    "        y_train_c = 1*(y_train==cat)\n",
    "        clf       = linear_model.LogisticRegression(tol          = 0.0001,\n",
    "                                                    max_iter     = 10000,\n",
    "                                                    random_state = None).fit(X_train, y_train_c)\n",
    "        ccp_train_list.append(  clf.predict_proba(X_train)[:,1])\n",
    "        ccp_valid_list.append(  clf.predict_proba(X_valid)[:,1])\n",
    "        ccp_test_list.append(   clf.predict_proba(X_test)[:,1])\n",
    "    \n",
    "    ' . Topic probability matrix'\n",
    "    ccp_train = pd.DataFrame(ccp_train_list).transpose()\n",
    "    ccp_valid = pd.DataFrame(ccp_valid_list).transpose()\n",
    "    ccp_test  = pd.DataFrame(ccp_test_list).transpose()\n",
    "    \n",
    "    'reset column index'\n",
    "    ccp_train.columns = categories['label'].to_list()\n",
    "    ccp_valid.columns = categories['label'].to_list()\n",
    "    ccp_test.columns = categories['label'].to_list()\n",
    "    \n",
    "    'Choosing your predictive category for the y '\n",
    "    ccp_train['label_hat'] =  ccp_train.idxmax(axis=1)\n",
    "    ccp_valid['label_hat'] =  ccp_valid.idxmax(axis=1)\n",
    "    ccp_test['label_hat']  =  ccp_test.idxmax(axis=1)    \n",
    "    \n",
    "    'caculate'\n",
    "    confusionmatrix=confusion_matrix(y_test,ccp_test['label_hat'] )\n",
    "    correct =  np.trace(confusionmatrix)\n",
    "    total = confusionmatrix.sum()\n",
    "    percent_accuracy = correct/total\n",
    "        \n",
    "    return(confusionmatrix,percent_accuracy)\n",
    "\n",
    "logistic_reg_classifier_mult_labels(X_train,y_train,X_valid,y_valid,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a68d911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find best k\n",
    "conf_matrices = []\n",
    "def find_best_k(X_train,X_valid,y_train,y_valid):\n",
    "    \n",
    "    k            = 1;\n",
    "    results_list = [];\n",
    "    max_k_nn     = 100\n",
    "    \n",
    "    for k in range(1,max_k_nn+1):\n",
    "       clf         = KNeighborsClassifier(n_neighbors=k).fit(X_train , y_train )\n",
    "       y_hat_valid = clf.predict(X_valid)\n",
    "       conf_matrices.append(confusion_matrix(y_valid, y_hat_valid ))\n",
    "   \n",
    "    for i in range(0,max_k_nn):\n",
    "       confusionmatrix=conf_matrices[i]\n",
    "       correct =  np.trace(confusionmatrix)\n",
    "       total = confusionmatrix.sum()\n",
    "       percent_accuracy = correct/total\n",
    "       result_for_i=[i+1,percent_accuracy]\n",
    "       results_list.append(result_for_i)\n",
    "            \n",
    "    for u in range(1,max_k_nn):\n",
    "        if results_list[u][1]>results_list[u-1][1]:\n",
    "            best=results_list[u]\n",
    "            \n",
    "    return best\n",
    "\n",
    "#find_best_k(X_train,X_valid,y_train,y_valid)\n",
    "best=find_best_k(X_train,X_valid,y_train,y_valid)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21704c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[69,  0,  0],\n",
       "        [ 0, 71,  8],\n",
       "        [ 1,  0, 80]]),\n",
       " 0.9606986899563319)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def K_NN_clf_result(best,X_train,y_train,X_valid,y_valid,X_test,y_test):\n",
    "    \n",
    "    best=find_best_k(X_train,X_valid,y_train,y_valid)[0]\n",
    "    \n",
    "    Y_hat_train = []\n",
    "    Y_hat_valid = []\n",
    "    Y_hat_test  = []\n",
    "    \n",
    "    clf = KNeighborsClassifier(n_neighbors=best).fit(X_train , y_train )\n",
    "    Y_hat_train.append(clf.predict(X_train))\n",
    "    Y_hat_valid.append(clf.predict(X_valid))\n",
    "    Y_hat_test.append(clf.predict(X_test))\n",
    "    \n",
    "    Y_hat_train = pd.DataFrame(Y_hat_train).transpose()\n",
    "    Y_hat_valid = pd.DataFrame(Y_hat_valid).transpose()\n",
    "    Y_hat_test = pd.DataFrame(Y_hat_test).transpose()\n",
    "    \n",
    "    Y_hat_train.columns = ['label_hat']\n",
    "    Y_hat_valid.columns = ['label_hat']\n",
    "    Y_hat_test.columns = ['label_hat']\n",
    "    \n",
    "    \n",
    "    confusionmatrix=confusion_matrix(y_test,Y_hat_test['label_hat'] )\n",
    "    correct =  np.trace(confusionmatrix)\n",
    "    total = confusionmatrix.sum()\n",
    "    percent_accuracy = correct/total\n",
    "\n",
    "    return (confusionmatrix,percent_accuracy)\n",
    "\n",
    "\n",
    "K_NN_clf_result(best,X_train,y_train,X_valid,y_valid,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec19ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
